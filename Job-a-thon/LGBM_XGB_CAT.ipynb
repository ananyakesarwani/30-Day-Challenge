{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'train_s3TEQDk.csv')\n",
    "test = pd.read_csv(r'test_mSzZ8RL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((245725, 11), (105312, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Channel_Code</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Credit_Product</th>\n",
       "      <th>Avg_Account_Balance</th>\n",
       "      <th>Is_Active</th>\n",
       "      <th>Is_Lead</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>13.860193</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>13.274205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>14.210464</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>13.061453</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>13.695360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>13.207004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>13.870709</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13.005209</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>14.057895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>14.515752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Region_Code  Occupation  Channel_Code  Vintage  \\\n",
       "0       0   73           18           1             2       43   \n",
       "1       0   30           27           2             0       32   \n",
       "2       0   56           18           3             2       26   \n",
       "3       1   34           20           2             0       19   \n",
       "4       0   30           32           2             0       33   \n",
       "5       1   56           11           3             0       32   \n",
       "6       1   62           32           1             2       20   \n",
       "7       0   48           15           3             2       13   \n",
       "8       0   40           33           3             1       38   \n",
       "9       0   55           18           3             1       49   \n",
       "\n",
       "   Credit_Product  Avg_Account_Balance  Is_Active  Is_Lead source  \n",
       "0               0            13.860193          0      0.0  train  \n",
       "1               0            13.274205          0      0.0  train  \n",
       "2               0            14.210464          1      0.0  train  \n",
       "3               0            13.061453          0      0.0  train  \n",
       "4               0            13.695360          0      0.0  train  \n",
       "5               0            13.207004          1      0.0  train  \n",
       "6               1            13.870709          1      1.0  train  \n",
       "7               0            13.005209          1      0.0  train  \n",
       "8               0            14.057895          0      0.0  train  \n",
       "9               1            14.515752          0      0.0  train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['source'] = 'train'\n",
    "test['source'] = 'test'\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351037, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                          0\n",
       "Gender                      0\n",
       "Age                         0\n",
       "Region_Code                 0\n",
       "Occupation                  0\n",
       "Channel_Code                0\n",
       "Vintage                     0\n",
       "Credit_Product          41847\n",
       "Avg_Account_Balance         0\n",
       "Is_Active                   0\n",
       "Is_Lead                105312\n",
       "source                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Credit_Product'].replace(np.nan,'Yes',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Avg_Account_Balance'] = np.log(data['Avg_Account_Balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['source']==\"train\"]\n",
    "test = data.loc[data['source']==\"test\"]\n",
    "\n",
    "#Drop unnecessary columns:\n",
    "test.drop(['Is_Lead','source'],axis=1,inplace=True)\n",
    "train.drop('source',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "train.drop('ID',axis=1,inplace=True)\n",
    "test.drop(\"ID\",axis=1,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "var_mod = ['Gender','Region_Code','Occupation','Channel_Code','Credit_Product','Is_Active']\n",
    "for i in var_mod:\n",
    "    train[i] = le.fit_transform(train[i])\n",
    "    test[i] = le.fit_transform(test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Is_Lead',axis=1)\n",
    "y = train['Is_Lead']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cross_val(X, y, model, params, folds=9):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=21)\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold: {fold}\")\n",
    "        x_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        x_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "        alg = model(**params)\n",
    "        alg.fit(x_train, y_train,\n",
    "                eval_set=[(x_test, y_test)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=400)\n",
    "\n",
    "        pred = alg.predict_proba(x_test)[:, 1]\n",
    "        roc_score = roc_auc_score(y_test, pred)\n",
    "        print(f\"roc_auc_score: {roc_score}\")\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    return alg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params= {'learning_rate': 0.045, \n",
    "             'n_estimators': 20000, \n",
    "             'max_bin': 94,\n",
    "             'num_leaves': 10, \n",
    "             'max_depth': 27, \n",
    "             'reg_alpha': 8.457, \n",
    "             'reg_lambda': 6.853, \n",
    "             'subsample': 0.749}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.378501\n",
      "[800]\tvalid_0's binary_logloss: 0.37827\n",
      "Early stopping, best iteration is:\n",
      "[802]\tvalid_0's binary_logloss: 0.378264\n",
      "roc_auc_score: 0.8539183817995556\n",
      "--------------------------------------------------\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.382606\n",
      "Early stopping, best iteration is:\n",
      "[524]\tvalid_0's binary_logloss: 0.382519\n",
      "roc_auc_score: 0.8500343931608946\n",
      "--------------------------------------------------\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.384762\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's binary_logloss: 0.38465\n",
      "roc_auc_score: 0.847290061663613\n",
      "--------------------------------------------------\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.383285\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's binary_logloss: 0.383167\n",
      "roc_auc_score: 0.8493604885557047\n",
      "--------------------------------------------------\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.380917\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's binary_logloss: 0.380823\n",
      "roc_auc_score: 0.8517737363514903\n",
      "--------------------------------------------------\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.382336\n",
      "Early stopping, best iteration is:\n",
      "[663]\tvalid_0's binary_logloss: 0.382243\n",
      "roc_auc_score: 0.8505607850758279\n",
      "--------------------------------------------------\n",
      "Fold: 6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.378841\n",
      "Early stopping, best iteration is:\n",
      "[685]\tvalid_0's binary_logloss: 0.378685\n",
      "roc_auc_score: 0.8541274022666261\n",
      "--------------------------------------------------\n",
      "Fold: 7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.38058\n",
      "[800]\tvalid_0's binary_logloss: 0.380368\n",
      "Early stopping, best iteration is:\n",
      "[832]\tvalid_0's binary_logloss: 0.38033\n",
      "roc_auc_score: 0.8533749327570593\n",
      "--------------------------------------------------\n",
      "Fold: 8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\tvalid_0's binary_logloss: 0.382945\n",
      "[800]\tvalid_0's binary_logloss: 0.382679\n",
      "Early stopping, best iteration is:\n",
      "[974]\tvalid_0's binary_logloss: 0.382578\n",
      "roc_auc_score: 0.8489208609089447\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgb_model = cross_val(X, y, LGBMClassifier, lgb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lgb = lgb_model.predict_proba(test)[:,1]\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv(r'sample_submission_eyYijxG.csv')\n",
    "sample_submission['Is_Lead'] = pred_test_lgb\n",
    "sample_submission.to_csv(f'submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params= {'n_estimators': 20000, \n",
    "             'max_depth': 6, \n",
    "             'learning_rate': 0.0201, \n",
    "             'reg_lambda': 29.326, \n",
    "             'subsample': 0.818, \n",
    "             'colsample_bytree': 0.235, \n",
    "             'colsample_bynode': 0.820, \n",
    "             'colsample_bylevel': 0.453}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "[19:42:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68616\n",
      "[400]\tvalidation_0-logloss:0.39841\n",
      "[800]\tvalidation_0-logloss:0.38836\n",
      "[1200]\tvalidation_0-logloss:0.38522\n",
      "[1600]\tvalidation_0-logloss:0.38395\n",
      "[2000]\tvalidation_0-logloss:0.38290\n",
      "[2400]\tvalidation_0-logloss:0.38231\n",
      "[2800]\tvalidation_0-logloss:0.38185\n",
      "[3200]\tvalidation_0-logloss:0.38163\n",
      "[3600]\tvalidation_0-logloss:0.38129\n",
      "[4000]\tvalidation_0-logloss:0.38109\n",
      "[4400]\tvalidation_0-logloss:0.38085\n",
      "[4461]\tvalidation_0-logloss:0.38084\n",
      "roc_auc_score: 0.852306070779921\n",
      "--------------------------------------------------\n",
      "Fold: 1\n",
      "[19:45:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68608\n",
      "[400]\tvalidation_0-logloss:0.40060\n",
      "[800]\tvalidation_0-logloss:0.39111\n",
      "[1200]\tvalidation_0-logloss:0.38838\n",
      "[1600]\tvalidation_0-logloss:0.38720\n",
      "[2000]\tvalidation_0-logloss:0.38626\n",
      "[2400]\tvalidation_0-logloss:0.38573\n",
      "[2800]\tvalidation_0-logloss:0.38534\n",
      "[3200]\tvalidation_0-logloss:0.38511\n",
      "[3600]\tvalidation_0-logloss:0.38477\n",
      "[4000]\tvalidation_0-logloss:0.38460\n",
      "[4400]\tvalidation_0-logloss:0.38440\n",
      "[4800]\tvalidation_0-logloss:0.38429\n",
      "[4847]\tvalidation_0-logloss:0.38430\n",
      "roc_auc_score: 0.8490677175744069\n",
      "--------------------------------------------------\n",
      "Fold: 2\n",
      "[19:48:52] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68608\n",
      "[400]\tvalidation_0-logloss:0.40243\n",
      "[800]\tvalidation_0-logloss:0.39303\n",
      "[1200]\tvalidation_0-logloss:0.39002\n",
      "[1600]\tvalidation_0-logloss:0.38882\n",
      "[2000]\tvalidation_0-logloss:0.38780\n",
      "[2400]\tvalidation_0-logloss:0.38728\n",
      "[2800]\tvalidation_0-logloss:0.38688\n",
      "[3200]\tvalidation_0-logloss:0.38667\n",
      "[3600]\tvalidation_0-logloss:0.38637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-61d6e9ce237b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-052042761fdb>\u001b[0m in \u001b[0;36mcross_val\u001b[0;34m(X, y, model, params, folds)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 verbose=400)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         )\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = cross_val(X, y, XGBClassifier, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params= {'n_estimators': 20000, \n",
    "                  'depth': 4, \n",
    "                  'learning_rate': 0.023, \n",
    "                  'colsample_bylevel': 0.655, \n",
    "                  'bagging_temperature': 0.921, \n",
    "                  'l2_leaf_reg': 10.133}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = cross_val(X, y, CatBoostClassifier, cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lgb = lgb_model.predict_proba(test)[:,1]\n",
    "pred_test_xgb = xgb_model.predict_proba(test)[:,1]\n",
    "pred_test_cat = cat_model.predict_proba(test)[:,1]\n",
    "prediction = (pred_test_lgb + pred_test_cat+pred_test_xgb)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(r'sample_submission_lgb_xgb_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
